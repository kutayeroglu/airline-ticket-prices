{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4381,
     "status": "ok",
     "timestamp": 1736799384789,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "R91hLUhkCdkk",
    "outputId": "bb12cc45-0785-4ed7-c91a-06563de3d261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive_root = '/content/drive'\n",
    "drive.mount(drive_root, force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736799384789,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "w_obZfZMG4nz"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.join(drive_root, 'MyDrive/Colab Notebooks/cmpe540/final-project')\n",
    "source_root = os.path.join(project_root, 'src')\n",
    "sys.path.append(source_root)\n",
    "data_folder_path = os.path.join(project_root, 'data')\n",
    "raw_data_folder_path = os.path.join(data_folder_path, 'raw')\n",
    "processed_data_folder_path = os.path.join(data_folder_path, 'processed')\n",
    "train_data_path = os.path.join(processed_data_folder_path, \"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6484,
     "status": "ok",
     "timestamp": 1736799391270,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "VrscNaqPIRxd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define the dataset\n",
    "class TicketPriceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "      self.X = torch.tensor(X, dtype=torch.float32)\n",
    "      self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class TicketPriceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(TicketPriceModel, self).__init__()\n",
    "      # 3-layer LSTM block\n",
    "      self.lstm = nn.LSTM(input_size=36, hidden_size=64, num_layers=3, batch_first=True)\n",
    "\n",
    "      # 3-layer 1D Conv block\n",
    "      self.conv1 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n",
    "      self.conv2 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "      self.conv3 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding=1)\n",
    "\n",
    "      # Fully connected layers\n",
    "      # Calculate the input size dynamically based on the output of the convolutional layers\n",
    "      self.fc1_input_size = self._get_fc1_input_size(torch.randn(1, 36))  # Pass a dummy input to calculate size\n",
    "      self.fc1 = nn.Linear(self.fc1_input_size, 128)\n",
    "      self.fc2 = nn.Linear(128, 1)  # Output: ticket price\n",
    "\n",
    "      # Activation function\n",
    "      self.relu = nn.ReLU()\n",
    "\n",
    "    def _get_fc1_input_size(self, x):\n",
    "      \"\"\"Calculates the input size for fc1 based on a dummy input.\"\"\"\n",
    "      x, _ = self.lstm(x)\n",
    "      if x.dim() == 2:\n",
    "        x = x.unsqueeze(1)\n",
    "      x = x.permute(0, 2, 1)\n",
    "      x = self.conv1(x)\n",
    "      x = F.relu(x)\n",
    "      x = self.conv2(x)\n",
    "      x = F.relu(x)\n",
    "      x = self.conv3(x)\n",
    "      x = F.relu(x)\n",
    "      return x.view(x.size(0), -1).shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "      # LSTM block\n",
    "      x, _ = self.lstm(x)\n",
    "\n",
    "      # Check if x has 3 dimensions, if not, add a dimension\n",
    "      if x.dim() == 2:  # If x has only 2 dimensions\n",
    "        x = x.unsqueeze(1)  # Add a dimension at position 1\n",
    "\n",
    "      # Permute for Conv1D: (batch_size, channels=64, seq_length)\n",
    "      x = x.permute(0, 2, 1)\n",
    "\n",
    "      # Pass through Conv layers\n",
    "      x = self.conv1(x)  # -> (batch_size, 32, seq_length')\n",
    "      x = F.relu(x)\n",
    "      x = self.conv2(x)  # -> (batch_size, 16, seq_length'')\n",
    "      x = F.relu(x)\n",
    "      x = self.conv3(x)  # -> (batch_size, 16, seq_length''')\n",
    "      x = F.relu(x)\n",
    "\n",
    "\n",
    "      # Flatten for fully connected layers\n",
    "      x = x.view(x.size(0), -1)  # (batch_size, 64 * 16)\n",
    "\n",
    "      # Fully-connected layers\n",
    "      x = self.fc1(x)\n",
    "      x = F.relu(x)\n",
    "      x = self.fc2(x)  # -> (batch_size, 1)\n",
    "\n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736799391271,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "H3l29hwyG6iU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3014,
     "status": "ok",
     "timestamp": 1736799394281,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "QlIjNlY_HHcC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: enter timestamp of the model to be evaluated\n",
    "timestamp = '20250113_191030'\n",
    "results_dir = os.path.join(project_root, 'results')\n",
    "\n",
    "test_path = os.path.join(results_dir, timestamp, \"test_data.csv\")\n",
    "test_set = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1736799738811,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "xQ86XUZhH9sQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def evaluate_model(model_path, test_loader, device):\n",
    "  \"\"\"Evaluates the model on the test set and calculates RMSE and Accuracy.\"\"\"\n",
    "\n",
    "  model = TicketPriceModel()\n",
    "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "  model.to(device)\n",
    "  model.eval() \n",
    "\n",
    "  predictions = []\n",
    "  actuals = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      # Ensure predictions are always 1-dimensional\n",
    "      pred = outputs.squeeze().cpu().numpy()\n",
    "      if pred.ndim == 0:\n",
    "          pred = pred[np.newaxis]  # Add a dimension if it's a scalar\n",
    "\n",
    "      predictions.append(pred)\n",
    "      actuals.extend(targets.cpu().numpy())\n",
    "\n",
    "  # Flatten predictions to a 1D array\n",
    "  predictions = np.concatenate(predictions)\n",
    "\n",
    "  rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "\n",
    "  # Prediction Accuracy (ACC)\n",
    "  tolerance = 0.1  # 10% tolerance\n",
    "  correct_predictions = np.sum(np.abs((np.array(predictions) - np.array(actuals))) <= tolerance * np.array(actuals))\n",
    "  accuracy = correct_predictions / len(actuals) if len(actuals) > 0 else 0\n",
    "\n",
    "  return rmse, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736799738812,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "nhBMwNeGIxyW"
   },
   "outputs": [],
   "source": [
    "def evaluation_pipeline(ndo, evaluation_model_path, device):\n",
    "  # Filter for specific ndo\n",
    "  ndo_filtered = test_set[test_set['ndo'] == ndo].iloc[]\n",
    "\n",
    "  # Create test loader object\n",
    "  batch_size = 2\n",
    "  test_loader = DataLoader(\n",
    "    TicketPriceDataset(ndo_filtered.drop(columns=['baseFare']).values, ndo_filtered['baseFare'].values),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    "  )\n",
    "\n",
    "  rmse, accuracy = evaluate_model(evaluation_model_path, test_loader, device)\n",
    "  print(f\"RMSE: {rmse:.4f}\")\n",
    "  print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1736799763401,
     "user": {
      "displayName": "Kutay Eroğlu",
      "userId": "12425207516295289282"
     },
     "user_tz": -180
    },
    "id": "oekejFuzU0dn",
    "outputId": "4a5a7631-4f36-47de-af9b-c832411b5402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for ndo 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7c37c47798b7>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 167.5585\n",
      "Accuracy: 0.0612\n",
      "Metrics for ndo 7\n",
      "RMSE: 132.9819\n",
      "Accuracy: 0.2785\n",
      "Metrics for ndo 30\n",
      "RMSE: 122.7148\n",
      "Accuracy: 0.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-7c37c47798b7>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
      "<ipython-input-9-7c37c47798b7>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Extract model to evaluate\n",
    "evaluation_timestamp = timestamp # TODO: change here if you want to evaluate a different model\n",
    "evaluation_model_path = os.path.join(results_dir, evaluation_timestamp, 'best_model.pth')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for ndo in [1, 7, 30]:\n",
    "  print(f\"Metrics for ndo {ndo}\")\n",
    "  evaluation_pipeline(ndo, evaluation_model_path, device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMrjakdcIcezrij5iVZtMhb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
