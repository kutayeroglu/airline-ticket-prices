{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ke2iPrvtd3zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84c0b24-0cb9-485e-fe3a-2b1f09cd254f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive_root = '/content/drive'\n",
        "drive.mount(drive_root, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "project_root = os.path.join(drive_root, 'MyDrive/Colab Notebooks/cmpe540/final-project')\n",
        "source_root = os.path.join(project_root, 'src')\n",
        "sys.path.append(source_root)\n",
        "data_folder_path = os.path.join(project_root, 'data')\n",
        "raw_data_folder_path = os.path.join(data_folder_path, 'raw')\n",
        "processed_data_folder_path = os.path.join(data_folder_path, 'processed')\n",
        "# output_file_path = os.path.join(processed_data_folder_path, \"train_data.csv\")"
      ],
      "metadata": {
        "id": "-zHaefBReE7C"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "input_file_path = os.path.join(processed_data_folder_path, \"new_filtered_flight.csv\")\n",
        "flight = pd.read_csv(input_file_path)"
      ],
      "metadata": {
        "id": "kb5ptw8seLkw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for busiest route\n",
        "flight_filtered = flight.copy()\n",
        "flight_filtered = flight_filtered[flight_filtered['route'] == 'ATL-LAX']\n",
        "flight_filtered = flight_filtered.drop(['route'], axis=1)\n",
        "\n",
        "# Change date columns to datetime\n",
        "for column in ['searchDate', 'flightDate']:\n",
        "  flight_filtered[column] = pd.to_datetime(flight_filtered[column], format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "ngO31ji07zX5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Number (of) Days (to) Operation = NDO\n",
        "flight_filtered['ndo'] = flight_filtered['flightDate'] - flight_filtered['searchDate']\n",
        "flight_filtered = flight_filtered.drop(['searchDate'], axis=1)"
      ],
      "metadata": {
        "id": "CNM4puYYirXI"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Remove rows which have ndo over 30, out-of-scope of this study\n",
        "# flight_filtered = flight_filtered[flight_filtered['ndo'] <= pd.Timedelta(days=30)]"
      ],
      "metadata": {
        "id": "wopTgnqBKKys"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arrival time creation\n",
        "flight_filtered['arrivalEpoch'] = flight_filtered['segmentsArrivalTimeEpochSeconds'].apply(\n",
        "    lambda x: int(x.split('||')[0])  # Convert to int after splitting\n",
        ")\n",
        "flight_filtered = flight_filtered.drop(['segmentsArrivalTimeEpochSeconds'], axis=1)\n",
        "\n",
        "# Convert epoch to datetime\n",
        "flight_filtered['arrivalDatetime'] = pd.to_datetime(flight_filtered['arrivalEpoch'], unit='s')\n",
        "flight_filtered = flight_filtered.drop(['arrivalEpoch'], axis=1)"
      ],
      "metadata": {
        "id": "hNur738cK8Ol"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract time (0.00, 24.00):24h from full date\n",
        "flight_filtered['arrivalTimeFloat'] = flight_filtered['arrivalDatetime'].dt.hour + (flight_filtered['arrivalDatetime'].dt.minute / 60)\n",
        "flight_filtered['arrivalTimeFloat'] = flight_filtered['arrivalTimeFloat'].round(2)\n",
        "flight_filtered = flight_filtered.drop(['arrivalDatetime'], axis=1)"
      ],
      "metadata": {
        "id": "PfvVylgaLEE2"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Departure\n",
        "flight_filtered['departureEpoch'] = flight_filtered['segmentsDepartureTimeEpochSeconds'].apply(\n",
        "    lambda x: int(x.split('||')[0])  # Convert to int after splitting\n",
        ")\n",
        "flight_filtered = flight_filtered.drop(['segmentsDepartureTimeEpochSeconds'], axis=1)\n",
        "\n",
        "# Convert epoch to datetime\n",
        "flight_filtered['departureDatetime'] = pd.to_datetime(flight_filtered['departureEpoch'], unit='s')\n",
        "flight_filtered = flight_filtered.drop(['departureEpoch'], axis=1)\n",
        "\n",
        "# Extract \"day-of-week\" (1 for Monday, 7 for Sunday)\n",
        "flight_filtered['dayOfWeek'] = flight_filtered['departureDatetime'].dt.isocalendar().day\n",
        "\n",
        "# Extract \"departure-time\" as hours (0.00 to 24.00 format)\n",
        "flight_filtered['departureTimeFloat'] = flight_filtered['departureDatetime'].dt.hour + (flight_filtered['departureDatetime'].dt.minute / 60)\n",
        "flight_filtered['departureTimeFloat'] = flight_filtered['departureTimeFloat'].round(2)\n",
        "\n",
        "# Remove rows where (possibly actual) departureDatetime does not match flightDate\n",
        "# This is a workaround since this was the only available timestamped data, but for\n",
        "# the scheduled times, it does not contain timestamp information\n",
        "flight_filtered['temp_flightDate'] = flight_filtered['departureDatetime'].dt.date\n",
        "flight_filtered[flight_filtered['temp_flightDate'] != flight_filtered['flightDate']]\n",
        "flight_filtered = flight_filtered.drop(['departureDatetime', 'temp_flightDate'], axis=1)"
      ],
      "metadata": {
        "id": "VZQTdUYa445y"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 'Departure date' feature: A certain date in the days investigated\n",
        "flight_filtered = flight_filtered.sort_values(by=['flightDate', 'departureTimeFloat'], ascending=[True, True])\n",
        "\n",
        "flight_filtered['NDepartureDate'] = (\n",
        "    flight_filtered['flightDate']\n",
        "    .rank(method='dense', ascending=True)\n",
        "    .astype(int)\n",
        ")"
      ],
      "metadata": {
        "id": "aWdjg9kYXMQ3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P_i_j = P_flightDate_ndo\n",
        "# Aggregate average fare for a given departure date\n",
        "lut = flight_filtered.groupby(['NDepartureDate', 'ndo'])['baseFare'].mean().reset_index()\n",
        "lut['baseFare'] = lut['baseFare'].round(2)\n",
        "\n",
        "# Convert ndo to int for easy coordinate-based (i,j) access\n",
        "lut['ndo'] = lut['ndo'].dt.days"
      ],
      "metadata": {
        "id": "z-m475dGPZpD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pivot to create lut_matrix\n",
        "lut_matrix = lut.pivot(\n",
        "    index='NDepartureDate',  # Use NDepartureDate as the row index\n",
        "    columns='ndo',           # Use ndo as the columns\n",
        "    values='baseFare'        # Use baseFare for values\n",
        ")"
      ],
      "metadata": {
        "id": "HBbdGUYkk_ei"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the days we have ndo30 - ndo1 data of\n",
        "unique_ndo_per_date = flight_filtered.groupby('flightDate')['ndo'].nunique().reset_index()\n",
        "unique_ndo_per_date.rename(columns={'ndo': 'uniqueNdoValues'}, inplace=True)\n",
        "eligible_dates = unique_ndo_per_date[unique_ndo_per_date['uniqueNdoValues'] >= 30]['flightDate'].tolist()\n",
        "flight_filtered = flight_filtered[flight_filtered['flightDate'].isin(eligible_dates)]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_G7OLSu7mK1X"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to compute b1 to b30 for a given i and j\n",
        "def compute_b_values(i, j, lut_matrix, max_b=30):\n",
        "    b_values = []\n",
        "    if i - 1 in lut_matrix.index:  # Check if previous row exists\n",
        "        row_prev = lut_matrix.loc[i - 1]\n",
        "        b_values += row_prev.iloc[max(0, j - max_b):j].tolist()\n",
        "\n",
        "    if len(b_values) < max_b and i in lut_matrix.index:  # Fill remaining from current row\n",
        "        row_curr = lut_matrix.loc[i]\n",
        "        b_values += row_curr.iloc[:max_b - len(b_values)].tolist()\n",
        "\n",
        "    # Pad with NaN if not enough values\n",
        "    return b_values[:max_b] + [np.nan] * (max_b - len(b_values))"
      ],
      "metadata": {
        "id": "T27dEmXyZ_Fg"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flight_filtered = flight_filtered[(flight_filtered['departureTimeFloat'] > 18.99) & (flight_filtered['departureTimeFloat'] < 21.00)]\n",
        "\n",
        "# Add b1 to b30 as new columns in `flight_filtered`\n",
        "flight_filtered['ndo'] = flight_filtered['ndo'].dt.days\n",
        "\n",
        "# i : Departure date, j: ndo\n",
        "for idx, row in flight_filtered.iterrows():\n",
        "    i = row['NDepartureDate']\n",
        "    j = row['ndo']\n",
        "    b_values = compute_b_values(i, j, lut_matrix)\n",
        "    for b_idx, b_val in enumerate(b_values, start=1):\n",
        "        flight_filtered.at[idx, f'b{b_idx}'] = b_val"
      ],
      "metadata": {
        "id": "CWRKh3d_aVWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49263a84-96da-43a8-bd7d-ff9b125cc463"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-75-9ed5d4124b49>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  flight_filtered['ndo'] = flight_filtered['ndo'].dt.days\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flight_filtered = flight_filtered[~flight_filtered.isna().any(axis=1)]"
      ],
      "metadata": {
        "id": "b9EXGTD6m1nQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Departure Date Time Series\n",
        "departure_date_series = flight_filtered.groupby('flightDate')['baseFare'].mean() # Or sum, median, etc. depending on what you want to aggregate\n",
        "departure_date_series = departure_date_series.resample('D').asfreq() # Important: Resample to daily frequency to have consistent time steps. Fills missing dates with NaN\n",
        "departure_date_series = departure_date_series.ffill() # Forward fill missing values.\n",
        "departure_date_series = departure_date_series.bfill() # Back fill missing values."
      ],
      "metadata": {
        "id": "yR5aC6S-_4Ee"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Days-to-Departure Time Series\n",
        "# Sort by ndo (days to departure) in descending order (far to near) WITHIN each flight date\n",
        "flight_filtered = flight_filtered.sort_values(by=['flightDate', 'ndo'], ascending=[True, False])"
      ],
      "metadata": {
        "id": "BZBWymNt_6kg"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **Handle duplicates within each flight date:**\n",
        "flight_filtered = flight_filtered.groupby(['flightDate', 'ndo']).agg({\n",
        "  'baseFare': 'mean'\n",
        "}).reset_index()"
      ],
      "metadata": {
        "id": "z3XuI-ZMEjmp"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list to hold all the individual days-to-departure series\n",
        "days_to_departure_series_list = []"
      ],
      "metadata": {
        "id": "RG1TkCUCBTE5"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for date, group in flight_filtered.groupby('flightDate'):\n",
        "    days_to_departure_series = group.set_index('ndo')['baseFare']\n",
        "    # Pad the series to a consistent length. This is crucial for feeding into neural networks.\n",
        "    max_ndo = flight_filtered['ndo'].max()\n",
        "    padded_series = days_to_departure_series.reindex(np.arange(max_ndo, -1, -1), fill_value=np.nan) # Pad from max ndo to 0\n",
        "    padded_series = padded_series.ffill() # Forward fill missing values.\n",
        "    padded_series = padded_series.bfill() # Back fill missing values.\n",
        "    days_to_departure_series_list.append(padded_series)"
      ],
      "metadata": {
        "id": "Ba2B8q9ABUgo"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list of series to a NumPy array for easier use in neural networks\n",
        "days_to_departure_matrix = np.array(days_to_departure_series_list)"
      ],
      "metadata": {
        "id": "_I9vLZsZBbwL"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Departure Date Time Series:\\n\", departure_date_series)\n",
        "print(\"\\nDays-to-Departure Matrix (each row is a flight):\\n\", days_to_departure_matrix)\n",
        "\n",
        "#Shape of the data\n",
        "print(\"Shape of Departure Date Time Series:\\n\", departure_date_series.shape)\n",
        "print(\"Shape of Days to Departure Matrix:\\n\", days_to_departure_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx_AGvxuBdly",
        "outputId": "aba20900-7a51-4d3b-96d5-7d7afd3af8b1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Departure Date Time Series:\n",
            " flightDate\n",
            "2022-05-19    432.635752\n",
            "2022-05-20    441.740099\n",
            "2022-05-21    381.004267\n",
            "2022-05-22    501.336250\n",
            "2022-05-23    458.435789\n",
            "                 ...    \n",
            "2022-10-18    289.848596\n",
            "2022-10-19    284.846225\n",
            "2022-10-20    252.153653\n",
            "2022-10-21    268.564344\n",
            "2022-10-22    295.425493\n",
            "Freq: D, Name: baseFare, Length: 157, dtype: float64\n",
            "\n",
            "Days-to-Departure Matrix (each row is a flight):\n",
            " [[362.976      362.976      362.976      ... 513.768      519.07\n",
            "  519.07      ]\n",
            " [335.195      335.195      335.195      ... 582.725      622.976\n",
            "  622.976     ]\n",
            " [324.03333333 324.03333333 324.03333333 ... 447.27333333 419.19636364\n",
            "  419.19636364]\n",
            " ...\n",
            " [174.53       174.53       174.53       ... 292.25       292.25\n",
            "  292.25      ]\n",
            " [224.84       224.84       224.84       ... 313.01461538 313.01461538\n",
            "  313.01461538]\n",
            " [294.58333333 294.58333333 294.58333333 ... 230.465      230.465\n",
            "  230.465     ]]\n",
            "Shape of Departure Date Time Series:\n",
            " (157,)\n",
            "Shape of Days to Departure Matrix:\n",
            " (157, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory to save the data\n",
        "output_dir = os.path.join(processed_data_folder_path, \"model_data\")\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# 1. Save Departure Date Time Series\n",
        "departure_date_series.to_csv(os.path.join(output_dir, \"departure_date_series.csv\"), header=True)\n",
        "\n",
        "# 2. Save Days-to-Departure Matrix\n",
        "np.save(os.path.join(output_dir, \"days_to_departure_matrix.npy\"), days_to_departure_matrix)\n",
        "\n",
        "print(f\"Data saved to {output_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzv_Kz_UFilh",
        "outputId": "f835f737-6d0f-4691-d48a-3753d1936040"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/Colab Notebooks/cmpe540/final-project/data/processed/model_data\n"
          ]
        }
      ]
    }
  ]
}